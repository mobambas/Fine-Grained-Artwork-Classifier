# -*- coding: utf-8 -*-
"""Artwork_Forgery_Detection_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WSBhpUt7rJGmN6CKi2CuGjGsWA0Rvdfx

# Using Finetuning to Develop a Parameter-Efficient Neural Newtork Model for Forgery Detection in Artworks

**Author:** [Shriyansh Singh](https://github.com/mobambas), Neev Ashish Dattani

**Date created:** 10/06/2024

**Last modified:** 10/06/2024

**Description:** This project aims to accurately determine the authenticity of famous art paintings around the globe by using machine learning. In today's world, the exponentially accelerated expansion of computational notions and their endless potential, alongside which an increasing number of unexplored machine learning applications are unravelled, we have identified this problem statement as relevant and challenging. Currently, the detection of forgery or replicas in museums is done by examining the painting in fine-detail by an expert curator. Ongoing research on automated art-piece identification is limited. Through machine learning, we aim to identify if two paintings are painted by the same person, and thus verify their genuineness. We believe that our proposed solution for detecting forgery in art paintings holds interesting applications for curators, art historians, connoisseurs and art lovers. Through our project, not only can forgery be detected, but also the subtle similarities and variations between different artists can be found out, through the characteristics and style of their paintings identified via machine learning.

# EXPLORATORY DATA ANALYSIS (EDA) TASK | WEEK 1

**STEP 1)** Plotting the class distribution for the chosen dataset(s), and comparing the distributions if necessary.

**STEP 2)** Studying different categories and plotting sample images of some categories.

**STEP 3)** Qualitative and quantitative analysis to visualise the differentiability between categories through parametetric fine-grained image analysis.

First, we need to download the WikiArt dataset (since the dataset is in the croissant format, it is available to download in the Hugging Face model hub). If we don't have the datasets library installed, install it using the following command in your terminal.
"""

!pip install datasets

"""Then download the dataset as follows:"""

from datasets import load_dataset

wiki_art = load_dataset("huggan/wikiart", split="train")

"""**STEP 1)**

Plotting the class distributions:
"""

import matplotlib.pyplot as plt

# Get the class labels and their counts
class_labels = wiki_art['style']
class_counts = []
for label in class_labels:
    class_counts.append((label, class_labels.count(label)))

# Plot the class distribution
plt.bar([x[0] for x in class_counts], [x[1] for x in class_counts])
plt.xlabel('Class Labels')
plt.ylabel('Count')
plt.title('Class Distribution of WikiArt Dataset')
plt.show()

"""**STEP 2)**

Studying different categories and plotting sample images as such:
"""

import matplotlib.pyplot as plt
import numpy as np

# Get the unique categories
categories = list(set(wiki_art['style']))

# Sample 100 images from each category
sample_size = 100

# Create a figure and subplots for each category
fig, axs = plt.subplots(nrows=len(categories), figsize=(10, 20))

for i, category in enumerate(categories):
    # Get the indices of the samples in the current category
    category_indices = [i for i, x in enumerate(wiki_art['style']) if x == category]

    # Sample the indices
    sample_indices = np.random.choice(category_indices, size=sample_size, replace=False)

    # Plot the sample images
    for index in sample_indices:
        axs[i].imshow(wiki_art['image'][index])
        axs[i].axis('off')

# Show the figure
plt.show()